{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLOp3W1o5ENS",
        "outputId": "60849675-24d3-428a-94d3-15443be15fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 100 (delta 46), reused 77 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (100/100), 9.09 MiB | 8.74 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "/content/transformers/few_shot_learning\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cervs257/transformers\n",
        "%cd transformers/few_shot_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ba9jIIhI49Kr"
      },
      "outputs": [],
      "source": [
        "from scratch_transformer import MultiHeadAttentionBlock\n",
        "from data import create_weights, get_reg_data, get_nonlinear_data\n",
        "import numpy as np\n",
        "\n",
        "feature_size = 10\n",
        "output_size = 1\n",
        "M = 10\n",
        "N = 1000\n",
        "lr = 1e-3\n",
        "\n",
        "# linear attention params override\n",
        "la_params = create_weights(feature_size, output_size, N, lr)\n",
        "\n",
        "# get the data\n",
        "eval_data = get_reg_data(no_tasks=M, feature_size=feature_size, no_examples=N)\n",
        "\n",
        "\n",
        "# Create a MultiHeadAttentionBlock\n",
        "mha = MultiHeadAttentionBlock(\n",
        "    d_model=feature_size + 1, heads=1, dropout=0.0, softmax_att=False\n",
        ")  # (batch_size, seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JIeEmuz949Ks"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Now we will override the weights of the model to implement those that perform GD in the forward pass\n",
        "def override_weights(model, new_params, w_name):\n",
        "    w_name = \"Transformer_gd/multi_head_attention/\" + w_name\n",
        "    w_numpy = new_params[w_name][\"w\"]\n",
        "    w_tensor = torch.tensor(w_numpy, dtype=model.weight.dtype)\n",
        "    model.weight.data = w_tensor\n",
        "\n",
        "\n",
        "# Override the weights of the model\n",
        "override_weights(mha.w_q, la_params, \"query\")\n",
        "override_weights(mha.w_k, la_params, \"key\")\n",
        "override_weights(mha.w_v, la_params, \"value\")\n",
        "override_weights(mha.w_o, la_params, \"linear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JnmTyGrv49Ks"
      },
      "outputs": [],
      "source": [
        "def compute_loss(preds, targets):\n",
        "    \"\"\"Compute the MSE loss.\"\"\"\n",
        "    return 0.5 * np.sum((targets - preds) ** 2) / targets.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0fnTyjvR49Ks"
      },
      "outputs": [],
      "source": [
        "e_eval = torch.tensor(eval_data[0]).float()\n",
        "\n",
        "# Forward pass\n",
        "out = mha(e_eval, e_eval, e_eval)\n",
        "\n",
        "# Compare the output to the targets\n",
        "eval_targets = eval_data[1][:, -1]\n",
        "eval_preds = out[:, -1, -1] * (-1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC5hxQxF49Ks",
        "outputId": "075320df-c2e5-4ddd-af6d-847616df6571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for M: 10, N: 1000 is 0.288.\n"
          ]
        }
      ],
      "source": [
        "loss = compute_loss(eval_preds.detach().numpy(), eval_targets)\n",
        "print(f\"Loss for M: {M}, N: {N} is {loss:.3f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6xxrFe7R49Kt"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=None,\n",
        "    training_steps=1000,\n",
        "    linear_data=False,\n",
        "    model_type=\"attn\",\n",
        "    mask=None,\n",
        "    stocks_train=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    param model_type: str, \"attn\" or \"transformer\"\n",
        "    \"\"\"\n",
        "    assert model_type in [\n",
        "        \"attn\",\n",
        "        \"transformer\",\n",
        "    ], \"model_type must be 'attn' or 'transformer'\"\n",
        "    if stocks_train is not None:\n",
        "        assert eval_data is not None, \"No stock evaluation data provided.\"\n",
        "    eval_losses = []\n",
        "    lowest_loss = 1e9\n",
        "\n",
        "    # Move the model to device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Training on {device}.\")\n",
        "\n",
        "    # If using stock data, we're predicting 5 outomes\n",
        "    if stocks_train is not None:\n",
        "        no_outcomes = 5\n",
        "    else:\n",
        "        no_outcomes = 1\n",
        "\n",
        "    # Get the evaluation data if it is not provided\n",
        "    if eval_data is None:\n",
        "        if linear_data:\n",
        "            eval_data = get_reg_data(\n",
        "                no_tasks=M, feature_size=feature_size, no_examples=N\n",
        "            )\n",
        "        else:\n",
        "            eval_data = get_nonlinear_data(\n",
        "                no_tasks=M, feature_size=feature_size, no_examples=N\n",
        "            )\n",
        "    assert eval_data is not None, \"No evaluation data provided.\"\n",
        "    e_eval = torch.tensor(eval_data[0]).float().to(device)\n",
        "    eval_targets = (\n",
        "        torch.tensor(eval_data[1][:, -no_outcomes:]).float().to(device)\n",
        "    )  # change for stocks\n",
        "\n",
        "    # Define lr scheduler\n",
        "    scheduler = StepLR(optimizer, step_size=1000, gamma=0.5)\n",
        "\n",
        "    for step in tqdm(range(training_steps + 1)):\n",
        "        # Generate train data\n",
        "        if stocks_train is not None:\n",
        "            train_data = stocks_train\n",
        "        elif linear_data:\n",
        "            train_data = get_reg_data(\n",
        "                no_tasks=M, feature_size=feature_size, no_examples=N\n",
        "            )\n",
        "        else:\n",
        "            train_data = get_nonlinear_data(\n",
        "                no_tasks=M, feature_size=feature_size, no_examples=N\n",
        "            )\n",
        "        e_train = torch.tensor(train_data[0]).float().to(device)\n",
        "        targets = (\n",
        "            torch.tensor(train_data[1][:, -no_outcomes:]).float().to(device)\n",
        "        )  # change for stocks\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        if model_type == \"attn\":\n",
        "            out = model(e_train, e_train, e_train, mask)\n",
        "        else:\n",
        "            out = model(e_train, mask)\n",
        "        preds = out[:, -1, -no_outcomes:] * (-1.0)  # change for stocks\n",
        "        loss = criterion(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluate\n",
        "        if step % 100 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if model_type == \"attn\":\n",
        "                    ev_preds = model(e_eval, e_eval, e_eval)\n",
        "                else:\n",
        "                    ev_preds = model(e_eval, None)  # no mask in evaluation mode\n",
        "                ev_preds = ev_preds[:, -1, -no_outcomes:] * (-1.0)  # change for stocks\n",
        "                eval_loss = criterion(ev_preds, eval_targets)\n",
        "                eval_losses.append(eval_loss)\n",
        "            model.train()\n",
        "            if eval_loss < lowest_loss:\n",
        "                lowest_loss = eval_loss\n",
        "                if stocks_train is not None:\n",
        "                    data_type = \"stocks\"\n",
        "                elif linear_data:\n",
        "                    data_type = \"lin_data\"\n",
        "                else:\n",
        "                    data_type = \"nonlin_data\"\n",
        "                if model_type == \"transformer\":\n",
        "                    att = \"transformer\"\n",
        "                elif model.softmax_att:\n",
        "                    att = \"softmax_attn\"\n",
        "                else:\n",
        "                    att = \"linear_attn\"\n",
        "                path = f\"models/{att}-{data_type}.pth\"\n",
        "                torch.save(model.state_dict(), path)\n",
        "            print(f\"Step {step}, Train Loss: {loss.item():.3f}\")\n",
        "            print(f\"Step {step}, Eval Loss: {eval_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFEqqs2G49Kt",
        "outputId": "38b5f38b-38bc-4b93-b7fb-813365214bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 16/1001 [00:00<00:33, 29.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss: 0.774\n",
            "Step 0, Eval Loss: 0.526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 128/1001 [00:01<00:06, 136.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Train Loss: 0.152\n",
            "Step 100, Eval Loss: 0.086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 224/1001 [00:02<00:05, 152.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss: 0.033\n",
            "Step 200, Eval Loss: 0.039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 320/1001 [00:02<00:04, 151.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Train Loss: 0.033\n",
            "Step 300, Eval Loss: 0.023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 417/1001 [00:03<00:03, 156.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss: 0.029\n",
            "Step 400, Eval Loss: 0.024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 532/1001 [00:04<00:02, 159.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Train Loss: 0.019\n",
            "Step 500, Eval Loss: 0.023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 629/1001 [00:04<00:02, 150.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss: 0.012\n",
            "Step 600, Eval Loss: 0.021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 723/1001 [00:05<00:01, 148.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Train Loss: 0.010\n",
            "Step 700, Eval Loss: 0.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 816/1001 [00:05<00:01, 143.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Train Loss: 0.027\n",
            "Step 800, Eval Loss: 0.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 929/1001 [00:06<00:00, 149.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Train Loss: 0.008\n",
            "Step 900, Eval Loss: 0.018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1001/1001 [00:07<00:00, 138.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Train Loss: 0.007\n",
            "Step 1000, Eval Loss: 0.026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Now let's explore training the model\n",
        "import torch.optim as optim\n",
        "\n",
        "# Train\n",
        "optimizer = optim.Adam(mha.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "training_steps = 1000\n",
        "\n",
        "train(\n",
        "    mha,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=eval_data,\n",
        "    training_steps=training_steps,\n",
        "    linear_data=True,\n",
        "    model_type=\"attn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ity6FBVo49Kt",
        "outputId": "c0ff641c-3765-46c7-d87d-157c97525b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss pre override for M: 10, N: 1000 is 425.128.\n",
            "Loss with GD weights for M: 10, N: 1000 is 0.432.\n"
          ]
        }
      ],
      "source": [
        "lr = 5e-4\n",
        "# Let's do the same but with non linear data\n",
        "eval_nl_data = get_nonlinear_data(no_tasks=M, feature_size=feature_size, no_examples=N)\n",
        "e_eval_nl = torch.tensor(eval_nl_data[0]).float()\n",
        "\n",
        "# Create a MultiHeadAttentionBlock\n",
        "mha_nl = MultiHeadAttentionBlock(\n",
        "    d_model=feature_size + 1, heads=1, dropout=0.0, softmax_att=False\n",
        ")  # (batch_size, seq_len, d_model)\n",
        "\n",
        "# Forward pass pre override\n",
        "out_nl = mha_nl(e_eval_nl, e_eval_nl, e_eval_nl)\n",
        "\n",
        "# Compare the output to the targets\n",
        "eval_nl_targets = eval_nl_data[1][:, -1]\n",
        "eval_nl_preds = out_nl[:, -1, -1] * (-1.0)\n",
        "\n",
        "loss_nl = compute_loss(eval_nl_preds.detach().numpy(), eval_nl_targets)\n",
        "print(f\"Loss pre override for M: {M}, N: {N} is {loss_nl:.3f}.\")\n",
        "\n",
        "# Override the weights of the model\n",
        "override_weights(mha_nl.w_q, la_params, \"query\")\n",
        "override_weights(mha_nl.w_k, la_params, \"key\")\n",
        "override_weights(mha_nl.w_v, la_params, \"value\")\n",
        "override_weights(mha_nl.w_o, la_params, \"linear\")\n",
        "\n",
        "# Forward pass\n",
        "out_nl = mha_nl(e_eval_nl, e_eval_nl, e_eval_nl)\n",
        "\n",
        "# Compare the output to the targets\n",
        "eval_nl_targets = eval_nl_data[1][:, -1]\n",
        "eval_nl_preds = out_nl[:, -1, -1] * (-1.0)\n",
        "\n",
        "loss_nl = compute_loss(eval_nl_preds.detach().numpy(), eval_nl_targets)\n",
        "print(f\"Loss with GD weights for M: {M}, N: {N} is {loss_nl:.3f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6CSkn2F49Kt",
        "outputId": "043aafa4-9b3d-4844-d9cb-b5693f8eb93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/3001 [00:00<05:49,  8.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss: 0.641\n",
            "Step 0, Eval Loss: 5.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 103/3001 [00:12<04:49, 10.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Train Loss: 1.100\n",
            "Step 100, Eval Loss: 1.027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 203/3001 [00:23<04:47,  9.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss: 1.471\n",
            "Step 200, Eval Loss: 1.128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 303/3001 [00:35<04:35,  9.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Train Loss: 2.686\n",
            "Step 300, Eval Loss: 1.232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 402/3001 [00:47<04:45,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss: 0.690\n",
            "Step 400, Eval Loss: 1.062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 503/3001 [00:58<04:03, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Train Loss: 1.851\n",
            "Step 500, Eval Loss: 0.996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 602/3001 [01:16<04:07,  9.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss: 1.104\n",
            "Step 600, Eval Loss: 1.753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 701/3001 [01:31<10:57,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Train Loss: 3.782\n",
            "Step 700, Eval Loss: 1.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 803/3001 [01:46<03:46,  9.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Train Loss: 1.036\n",
            "Step 800, Eval Loss: 1.150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 902/3001 [01:58<03:44,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Train Loss: 0.997\n",
            "Step 900, Eval Loss: 1.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1002/3001 [02:10<04:03,  8.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Train Loss: 1.066\n",
            "Step 1000, Eval Loss: 1.069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1102/3001 [02:22<05:31,  5.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1100, Train Loss: 0.867\n",
            "Step 1100, Eval Loss: 1.165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 1202/3001 [02:33<05:09,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1200, Train Loss: 0.582\n",
            "Step 1200, Eval Loss: 1.082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 1302/3001 [02:44<03:01,  9.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1300, Train Loss: 0.462\n",
            "Step 1300, Eval Loss: 1.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 1402/3001 [02:55<02:45,  9.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1400, Train Loss: 0.371\n",
            "Step 1400, Eval Loss: 1.039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1503/3001 [03:07<02:27, 10.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1500, Train Loss: 1.739\n",
            "Step 1500, Eval Loss: 0.987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 1603/3001 [03:18<02:20,  9.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1600, Train Loss: 0.744\n",
            "Step 1600, Eval Loss: 1.002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 1702/3001 [03:30<02:32,  8.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1700, Train Loss: 0.642\n",
            "Step 1700, Eval Loss: 1.103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1803/3001 [03:41<02:01,  9.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1800, Train Loss: 1.527\n",
            "Step 1800, Eval Loss: 0.970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 1902/3001 [03:52<02:15,  8.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1900, Train Loss: 0.244\n",
            "Step 1900, Eval Loss: 0.986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2002/3001 [04:04<01:44,  9.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2000, Train Loss: 0.267\n",
            "Step 2000, Eval Loss: 1.062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 2103/3001 [04:15<01:31,  9.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2100, Train Loss: 0.729\n",
            "Step 2100, Eval Loss: 1.007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 2201/3001 [04:26<01:50,  7.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2200, Train Loss: 0.607\n",
            "Step 2200, Eval Loss: 0.990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 2302/3001 [04:37<01:52,  6.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2300, Train Loss: 0.905\n",
            "Step 2300, Eval Loss: 1.007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 2402/3001 [04:48<01:06,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2400, Train Loss: 0.412\n",
            "Step 2400, Eval Loss: 0.993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 2502/3001 [04:59<00:52,  9.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2500, Train Loss: 0.339\n",
            "Step 2500, Eval Loss: 1.019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 2601/3001 [05:10<00:39, 10.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2600, Train Loss: 0.194\n",
            "Step 2600, Eval Loss: 1.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 2702/3001 [05:21<00:29, 10.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2700, Train Loss: 1.356\n",
            "Step 2700, Eval Loss: 0.966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2802/3001 [05:33<00:21,  9.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2800, Train Loss: 1.046\n",
            "Step 2800, Eval Loss: 1.022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 2902/3001 [05:44<00:10,  9.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2900, Train Loss: 1.530\n",
            "Step 2900, Eval Loss: 0.982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3001/3001 [05:56<00:00,  8.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3000, Train Loss: 0.791\n",
            "Step 3000, Eval Loss: 1.021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lr = 5e-4\n",
        "optimizer = optim.Adam(mha_nl.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "training_steps = 3000\n",
        "\n",
        "# Now let's explore training the model\n",
        "train(\n",
        "    mha_nl,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=eval_nl_data,\n",
        "    training_steps=training_steps,\n",
        "    linear_data=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqMN7ZO049Kt",
        "outputId": "71e6e79e-cf27-477d-8cb3-22c16dc0ee8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/1001 [00:00<02:02,  8.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss: 1.214\n",
            "Step 0, Eval Loss: 0.925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 102/1001 [00:11<01:43,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Train Loss: 0.657\n",
            "Step 100, Eval Loss: 0.816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 203/1001 [00:22<01:19, 10.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss: 0.845\n",
            "Step 200, Eval Loss: 0.781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 302/1001 [00:34<01:20,  8.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Train Loss: 1.154\n",
            "Step 300, Eval Loss: 0.767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 402/1001 [00:45<01:41,  5.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss: 0.835\n",
            "Step 400, Eval Loss: 0.775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 503/1001 [00:55<00:48, 10.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Train Loss: 0.927\n",
            "Step 500, Eval Loss: 0.796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 602/1001 [01:06<00:40,  9.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss: 1.260\n",
            "Step 600, Eval Loss: 0.743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 703/1001 [01:18<00:30,  9.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Train Loss: 0.980\n",
            "Step 700, Eval Loss: 0.664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 802/1001 [01:29<00:21,  9.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Train Loss: 0.829\n",
            "Step 800, Eval Loss: 0.620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 902/1001 [01:41<00:11,  8.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Train Loss: 0.726\n",
            "Step 900, Eval Loss: 0.647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1001/1001 [01:53<00:00,  8.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Train Loss: 1.069\n",
            "Step 1000, Eval Loss: 0.662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Finally let's use softmax attention\n",
        "# Create a MultiHeadAttentionBlock\n",
        "mha_nl_sa = MultiHeadAttentionBlock(\n",
        "    d_model=feature_size + 1, heads=1, dropout=0.0, softmax_att=True\n",
        ")  # (batch_size, seq_len, d_model)\n",
        "\n",
        "optimizer = optim.Adam(mha_nl_sa.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "training_steps = 1000\n",
        "\n",
        "# Training the model\n",
        "train(\n",
        "    mha_nl_sa,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=None,\n",
        "    training_steps=training_steps,\n",
        "    linear_data=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AtnZfAP0M4a6"
      },
      "outputs": [],
      "source": [
        "from scratch_transformer import (\n",
        "    LayerNormalization,\n",
        "    FeedForwardBlock,\n",
        "    ResidualConnection,\n",
        "    EncoderBlock,\n",
        "    MultiHeadAttentionBlock,\n",
        ")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from data import get_nonlinear_data\n",
        "\n",
        "feature_size = 10\n",
        "output_size = 1\n",
        "M = 10\n",
        "N = 1000\n",
        "lr = 1e-4\n",
        "dropout = 0.2\n",
        "mask = None\n",
        "\n",
        "# get the data\n",
        "eval_data = get_nonlinear_data(no_tasks=M, feature_size=feature_size, no_examples=N)\n",
        "e = torch.tensor(eval_data[0]).float()\n",
        "\n",
        "\n",
        "# MLP dimension usually 4 times the d_model\n",
        "# Residual connection already contains layer normalizations\n",
        "\n",
        "# Start with Self Attention\n",
        "mha = MultiHeadAttentionBlock(\n",
        "    d_model=feature_size + 1, heads=1, dropout=dropout, softmax_att=True\n",
        ")  # (batch_size, seq_len, d_model)\n",
        "\n",
        "\n",
        "# Feed Forward\n",
        "ff = FeedForwardBlock(\n",
        "    d_model=feature_size + 1, d_ff=4 * (feature_size + 1), dropout=dropout\n",
        ")  # (batch_size, seq_len, d_model\n",
        "\n",
        "\n",
        "# Create an EncoderBlock\n",
        "eb = EncoderBlock(\n",
        "    self_attention_block=mha,\n",
        "    feed_forward_block=ff,\n",
        "    dropout=dropout,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj8a7p3jM4a7",
        "outputId": "f874cb33-5743-45f9-a129-b6173e832307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of parameters: 1555\n",
            "Training on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/1001 [00:01<07:23,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss: 18.331\n",
            "Step 0, Eval Loss: 4.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 102/1001 [00:12<01:40,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Train Loss: 3.360\n",
            "Step 100, Eval Loss: 4.210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 203/1001 [00:24<01:19, 10.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss: 2.359\n",
            "Step 200, Eval Loss: 3.661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 302/1001 [00:36<01:19,  8.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Train Loss: 29.277\n",
            "Step 300, Eval Loss: 3.126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 403/1001 [00:47<01:01,  9.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss: 8.752\n",
            "Step 400, Eval Loss: 2.586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 502/1001 [00:59<00:55,  8.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Train Loss: 3.398\n",
            "Step 500, Eval Loss: 2.059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 601/1001 [01:10<00:44,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss: 8.046\n",
            "Step 600, Eval Loss: 1.619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 701/1001 [01:22<00:31,  9.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Train Loss: 17.576\n",
            "Step 700, Eval Loss: 1.217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 802/1001 [01:33<00:32,  6.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Train Loss: 9.904\n",
            "Step 800, Eval Loss: 0.878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 902/1001 [01:45<00:16,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Train Loss: 2.503\n",
            "Step 900, Eval Loss: 0.605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1001/1001 [01:56<00:00,  8.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Train Loss: 1.350\n",
            "Step 1000, Eval Loss: 0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_steps = 1000\n",
        "optimizer = optim.Adam(eb.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "total_params = sum(p.numel() for p in eb.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "# Training the model\n",
        "train(\n",
        "    eb,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=None,\n",
        "    training_steps=training_steps,\n",
        "    linear_data=False,\n",
        "    model_type=\"transformer\",\n",
        "    mask=mask,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from data import get_stock_data\n",
        "\n",
        "path = \"data/stocks.csv\"\n",
        "spy_train, spy_eval = get_stock_data(path, ticker=\"SPY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TQ_9bwwMM4a8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "\n",
        "# mask = create_look_ahead_mask(spy_train[0].shape[1])\n",
        "\n",
        "\n",
        "# def create_look_ahead_mask(batch_size, seq_len):\n",
        "#     mask = torch.triu(torch.ones((batch_size, seq_len, seq_len)), diagonal=1)\n",
        "#     return mask  # (batch_size, seq_len, seq_len)\n",
        "\n",
        "# # Masks for the transformer\n",
        "# mask = create_look_ahead_mask(spy_np.shape[0], spy_np.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SqJUj-V4M4a8"
      },
      "outputs": [],
      "source": [
        "from scratch_transformer import (\n",
        "    LayerNormalization,\n",
        "    FeedForwardBlock,\n",
        "    ResidualConnection,\n",
        "    EncoderBlock,\n",
        "    MultiHeadAttentionBlock,\n",
        "    Encoder,\n",
        ")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "feature_size = 10\n",
        "output_size = 1\n",
        "dropout = 0.2\n",
        "mask = None\n",
        "heads = 5\n",
        "layers = 12\n",
        "\n",
        "# convert to tensor\n",
        "e = torch.tensor(spy_eval[0]).float()\n",
        "et = torch.tensor(spy_train[0]).float()\n",
        "\n",
        "\n",
        "# MLP dimension usually 4 times the d_model\n",
        "# Residual connection already contains layer normalizations\n",
        "\n",
        "# Start with Self Attention\n",
        "mha = MultiHeadAttentionBlock(\n",
        "    d_model=feature_size,\n",
        "    heads=heads,\n",
        "    dropout=dropout,\n",
        "    softmax_att=True,\n",
        ")  # (batch_size, seq_len, d_model)\n",
        "\n",
        "# out = mha(e, e, e)\n",
        "out = mha(et, et, et, mask)\n",
        "\n",
        "# Feed Forward\n",
        "ff = FeedForwardBlock(\n",
        "    d_model=feature_size, d_ff=4 * feature_size, dropout=dropout\n",
        ")  # (batch_size, seq_len, d_model\n",
        "\n",
        "\n",
        "# Create an EncoderBlock\n",
        "eb = EncoderBlock(\n",
        "    self_attention_block=mha,\n",
        "    feed_forward_block=ff,\n",
        "    dropout=dropout,\n",
        ")\n",
        "\n",
        "encoder_blocks = []\n",
        "for _ in range(layers):\n",
        "    encoder_self_attention_block = MultiHeadAttentionBlock(\n",
        "        d_model=feature_size, heads=heads, dropout=dropout, softmax_att=True\n",
        "    )\n",
        "    encoder_feed_forward_block = FeedForwardBlock(\n",
        "        d_model=feature_size, d_ff=4 * feature_size, dropout=dropout\n",
        "    )\n",
        "    encoder_block = EncoderBlock(\n",
        "        self_attention_block=encoder_self_attention_block,\n",
        "        feed_forward_block=encoder_feed_forward_block,\n",
        "        dropout=dropout,\n",
        "    )\n",
        "    encoder_blocks.append(encoder_block)\n",
        "\n",
        "# Don't worry about Encoder, it's just predefined in scratch_transformer\n",
        "decoder = Encoder(\n",
        "    nn.ModuleList(encoder_blocks),\n",
        ")\n",
        "\n",
        "# out = decoder(et, mask)\n",
        "\n",
        "for p in decoder.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "# Compare the output to the targets\n",
        "# eval_targets = spy_eval[1]\n",
        "# eval_preds = out[:, -1, -5:] * (-1.0)\n",
        "\n",
        "# loss = compute_loss(eval_preds.detach().numpy(), eval_targets)\n",
        "# print(f\"Loss is {loss:.3f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqDM_1krM4a8",
        "outputId": "1020d7f2-1b05-420d-f799-e510a6332df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of parameters: 15530\n",
            "Training on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/5001 [00:00<05:31, 15.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss: 0.865\n",
            "Step 0, Eval Loss: 0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 104/5001 [00:04<03:45, 21.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Train Loss: 0.074\n",
            "Step 100, Eval Loss: 0.055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 203/5001 [00:08<03:40, 21.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss: 0.058\n",
            "Step 200, Eval Loss: 0.045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 305/5001 [00:14<03:27, 22.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Train Loss: 0.040\n",
            "Step 300, Eval Loss: 0.013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 404/5001 [00:18<03:17, 23.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss: 0.017\n",
            "Step 400, Eval Loss: 0.013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 504/5001 [00:23<05:21, 13.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Train Loss: 0.019\n",
            "Step 500, Eval Loss: 0.008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 603/5001 [00:27<03:15, 22.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss: 0.016\n",
            "Step 600, Eval Loss: 0.008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 705/5001 [00:31<03:08, 22.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Train Loss: 0.011\n",
            "Step 700, Eval Loss: 0.007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 805/5001 [00:36<03:12, 21.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Train Loss: 0.008\n",
            "Step 800, Eval Loss: 0.007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 904/5001 [00:41<03:07, 21.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Train Loss: 0.011\n",
            "Step 900, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1003/5001 [00:45<02:59, 22.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Train Loss: 0.010\n",
            "Step 1000, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 1103/5001 [00:50<02:51, 22.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1100, Train Loss: 0.009\n",
            "Step 1100, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 1205/5001 [00:54<02:59, 21.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1200, Train Loss: 0.008\n",
            "Step 1200, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 1305/5001 [01:00<03:25, 17.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1300, Train Loss: 0.007\n",
            "Step 1300, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 1405/5001 [01:04<02:46, 21.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1400, Train Loss: 0.016\n",
            "Step 1400, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 1504/5001 [01:09<02:36, 22.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1500, Train Loss: 0.020\n",
            "Step 1500, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1603/5001 [01:14<02:30, 22.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1600, Train Loss: 0.006\n",
            "Step 1600, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 1705/5001 [01:18<02:26, 22.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1700, Train Loss: 0.006\n",
            "Step 1700, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 1803/5001 [01:22<03:01, 17.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1800, Train Loss: 0.016\n",
            "Step 1800, Eval Loss: 0.007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 1905/5001 [01:27<02:08, 24.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1900, Train Loss: 0.005\n",
            "Step 1900, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2004/5001 [01:31<02:04, 23.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2000, Train Loss: 0.012\n",
            "Step 2000, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 2104/5001 [01:36<02:38, 18.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2100, Train Loss: 0.007\n",
            "Step 2100, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 2203/5001 [01:40<02:02, 22.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2200, Train Loss: 0.006\n",
            "Step 2200, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 2305/5001 [01:44<01:53, 23.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2300, Train Loss: 0.007\n",
            "Step 2300, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 2405/5001 [01:49<01:49, 23.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2400, Train Loss: 0.005\n",
            "Step 2400, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2504/5001 [01:53<01:45, 23.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2500, Train Loss: 0.005\n",
            "Step 2500, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 2603/5001 [01:58<02:18, 17.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2600, Train Loss: 0.005\n",
            "Step 2600, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 2705/5001 [02:03<01:38, 23.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2700, Train Loss: 0.004\n",
            "Step 2700, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 2804/5001 [02:07<01:33, 23.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2800, Train Loss: 0.005\n",
            "Step 2800, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 2902/5001 [02:12<02:20, 14.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2900, Train Loss: 0.008\n",
            "Step 2900, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3005/5001 [02:16<01:22, 24.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3000, Train Loss: 0.004\n",
            "Step 3000, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 3104/5001 [02:21<01:21, 23.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3100, Train Loss: 0.005\n",
            "Step 3100, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 3205/5001 [02:25<01:16, 23.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3200, Train Loss: 0.004\n",
            "Step 3200, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 3304/5001 [02:30<01:11, 23.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3300, Train Loss: 0.003\n",
            "Step 3300, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 3403/5001 [02:34<01:08, 23.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3400, Train Loss: 0.005\n",
            "Step 3400, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 3504/5001 [02:39<01:02, 23.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3500, Train Loss: 0.006\n",
            "Step 3500, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 3603/5001 [02:43<00:59, 23.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3600, Train Loss: 0.005\n",
            "Step 3600, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 3703/5001 [02:47<01:12, 17.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3700, Train Loss: 0.004\n",
            "Step 3700, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 3806/5001 [02:52<00:50, 23.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3800, Train Loss: 0.005\n",
            "Step 3800, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 3905/5001 [02:56<00:51, 21.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3900, Train Loss: 0.004\n",
            "Step 3900, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4003/5001 [03:02<00:44, 22.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4000, Train Loss: 0.006\n",
            "Step 4000, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 4105/5001 [03:07<00:38, 23.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4100, Train Loss: 0.003\n",
            "Step 4100, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 4204/5001 [03:12<00:46, 17.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4200, Train Loss: 0.003\n",
            "Step 4200, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 4305/5001 [03:16<00:29, 23.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4300, Train Loss: 0.003\n",
            "Step 4300, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 4404/5001 [03:20<00:25, 23.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4400, Train Loss: 0.003\n",
            "Step 4400, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 4505/5001 [03:25<00:25, 19.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4500, Train Loss: 0.004\n",
            "Step 4500, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 4604/5001 [03:29<00:16, 23.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4600, Train Loss: 0.003\n",
            "Step 4600, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 4705/5001 [03:34<00:12, 23.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4700, Train Loss: 0.004\n",
            "Step 4700, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 4805/5001 [03:39<00:08, 23.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4800, Train Loss: 0.007\n",
            "Step 4800, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 4904/5001 [03:43<00:04, 22.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4900, Train Loss: 0.004\n",
            "Step 4900, Eval Loss: 0.005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5001/5001 [03:47<00:00, 21.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 5000, Train Loss: 0.002\n",
            "Step 5000, Eval Loss: 0.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Train\n",
        "lr = 1e-3\n",
        "training_steps = 5000\n",
        "optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "total_params = sum(p.numel() for p in decoder.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "# Training the model\n",
        "train(\n",
        "    decoder,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    eval_data=spy_eval,\n",
        "    training_steps=training_steps,\n",
        "    linear_data=False,\n",
        "    model_type=\"transformer\",\n",
        "    mask=mask,\n",
        "    stocks_train=spy_train,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IEc9n2SM4a8",
        "outputId": "e979704c-766d-46bc-dcc3-5170adb0c18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval Loss: 0.005\n"
          ]
        }
      ],
      "source": [
        "# load the transformer-stocks.pth model\n",
        "decoder.load_state_dict(torch.load(\"models/transformer-stocks.pth\"))\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "decoder.to(device)\n",
        "# Evaluate the model\n",
        "decoder.eval()\n",
        "with torch.no_grad():\n",
        "    e_eval = torch.tensor(spy_eval[0]).float()\n",
        "    eval_preds = decoder(e_eval.to(device), None)[:, -1, -5:] * (-1.0)\n",
        "    eval_targets = torch.tensor(spy_eval[1]).float()\n",
        "    eval_loss = criterion(eval_preds, eval_targets.to(device))\n",
        "\n",
        "print(f\"Eval Loss: {eval_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we change the inputs to traditional x, y\n",
        "train = spy_train[0].reshape(-1, 10)\n",
        "test = spy_eval[0].reshape(-1, 10)\n",
        "\n",
        "x_train = train[:, :5]\n",
        "y_train = train[:, 5:]\n",
        "\n",
        "x_test = test[:, :5]\n",
        "y_test = test[:, 5:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_-rmyJoM4a8",
        "outputId": "a30c7b6b-1b67-4805-abc4-66e76bb391c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.013\n"
          ]
        }
      ],
      "source": [
        "# compare to XGBoost\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create the model\n",
        "model = XGBRegressor(\n",
        "    n_estimators=10000,\n",
        "    max_depth=100,\n",
        "    learning_rate=0.01,\n",
        "    objective=\"reg:squarederror\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"MSE: {mse:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3696, 5) (3696, 5)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "feature_size = 5\n",
        "output_size = 1\n",
        "hidden_size = 10\n",
        "num_layers = 12\n",
        "dropout = 0.2\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size, hidden_size, num_layers, batch_first=True, dropout=dropout\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "model = LSTMModel(feature_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Initialize the weights of the model\n",
        "for name, param in model.named_parameters():\n",
        "    if \"bias\" in name:\n",
        "        nn.init.constant_(param, 0.0)\n",
        "    elif \"weight\" in name:\n",
        "        nn.init.xavier_uniform_(param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cpu.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([64, 5])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "c:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([48, 5])) that is different to the input size (torch.Size([48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "c:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([300, 5])) that is different to the input size (torch.Size([300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss: 0.005716497700757764, Validation loss: 0.015798887237906456\n",
            "Epoch 101, Training loss: 0.005024593186982233, Validation loss: 0.015592684037983418\n",
            "Epoch 201, Training loss: 0.0046566800085891934, Validation loss: 0.014116360805928707\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 40\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[0;32m     43\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[1;32mc:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    372\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 373\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# call optimizer step pre hooks\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pre_hook \u001b[38;5;129;01min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_pre_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    376\u001b[0m         result \u001b[38;5;241m=\u001b[39m pre_hook(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
            "File \u001b[1;32mc:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:622\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m--> 622\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    624\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
            "File \u001b[1;32mc:\\Users\\cerva\\miniconda3\\lib\\site-packages\\torch\\_ops.py:513\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {device}.\")\n",
        "\n",
        "\n",
        "# Convert the data to tensors\n",
        "x_train_tensor = torch.tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.tensor(y_train).float()\n",
        "x_test_tensor = torch.tensor(x_test).float().to(device)\n",
        "y_test_tensor = torch.tensor(y_test).float()\n",
        "\n",
        "# Create a DataLoader\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "best_val_loss = 1e9\n",
        "num_epochs = 1000\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(x_test_tensor)\n",
        "            val_loss = criterion(val_outputs, y_test_tensor)\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}, Training loss: {running_loss / len(train_loader)}, Validation loss: {val_loss.item()}\"\n",
        "        )\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"models/lstm-stocks.pth\")\n",
        "        model.train()\n",
        "\n",
        "print(\"Finished Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
